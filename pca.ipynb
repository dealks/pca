{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('input.csv', header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce DF to Relevant Variables\n",
    "df_reduced = df[['CID', 'SALES','TRANS', 'QUANTITY', 'VISITS', 'CALLS', 'OFFERS'\n",
    "                ]]\n",
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating out the features\n",
    "features = ['SALES','TRANS', 'QUANTITY', 'VISITS', 'CALLS', 'OFFERS'\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Stats\n",
    "df_reduced.mean()\n",
    "df_reduced.std()\n",
    "\n",
    "df_stats = pd.concat([df_reduced.mean(),df_reduced.std()], axis=1).round(2)\n",
    "df_stats = df_stats.drop(['CID'])\n",
    "df_stats.columns=['MEANS', 'STD DEV']\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Separating out the features\n",
    "x = df_reduced.loc[:, features].values\n",
    "# Separating out the target\n",
    "y = df_reduced.loc[:,['CID']].values\n",
    "# Standardizing the features\n",
    "x_std = StandardScaler().fit_transform(x)\n",
    "x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covariance Matrix\n",
    "\n",
    "mean_vec = np.mean(x_std, axis=0)\n",
    "cov_mat = (x_std - mean_vec).T.dot((x_std - mean_vec)) / (x_std.shape[0]-1)\n",
    "print('Covariance matrix \\n%s' %cov_mat)\n",
    "\n",
    "cov_mat = np.cov(x_std.T)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Matrix\n",
    "cor_mat1 = np.corrcoef(x_std.T)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat1)\n",
    "\n",
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singular Vector Decomposition\n",
    "u,s,v = np.linalg.svd(x_std.T)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure Eigenvectors have the same unit length 1\n",
    "for ev in eig_vecs:\n",
    "    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
    "print('Everything ok!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples in descending order of explanatory power\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA().fit(x_std)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Function to draw attention to significant loadings\n",
    "# def color_significant_green(val):\n",
    "#     \"\"\"\n",
    "#     Takes a scalar and returns a string with\n",
    "#     the css property `'color: green'` for negative\n",
    "#     strings, black otherwise.\n",
    "#     \"\"\"\n",
    "#     color = 'green' if val <= -60 or val>=60 else 'black'\n",
    "#     return 'color: %s' % color\n",
    "\n",
    "def highlight_significant(val):\n",
    "    \"\"\"\n",
    "    Takes a scalar and returns a string with\n",
    "    the css property `'background-color: yellow'` for significant values, white otherwise.\n",
    "    \"\"\"\n",
    "    color ='yellow' if val <= -60 or val>=60 else 'white'\n",
    "    return 'background-color: %s' % color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Compute loadings A. May skip if you don't need to interpret PCs anyhow.\n",
    "# Loadings are eigenvectors normalized to respective eigenvalues: A value = V value * sqrt(L value)\n",
    "# Loadings are the covariances between variables and components.\n",
    "\n",
    "eig_vals_df = pd.DataFrame(np.array(eig_vals), columns=[\"Eigenvalues\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all vectors with values close to/greater than 1 \n",
    "num_signif_vectors = np.count_nonzero(np.where(eig_vals_df['Eigenvalues']>=.9))+1\n",
    "\n",
    "#PCs You Are Keeping\n",
    "eig_vals_df2 = eig_vals_df.nlargest(num_signif_vectors, columns=[\"Eigenvalues\"], keep='first')\n",
    "# eig_vals_df2 = np.where(eig_vals_df['Eigenvalues']>=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals_pc1 = eig_vals_df2.iloc[0:1,:]\n",
    "eig_vals_pc2 = eig_vals_df2.iloc[1:2,:]\n",
    "eig_vals_pc3 = eig_vals_df2.iloc[2:3,:]\n",
    "eig_vals_pc4 = eig_vals_df2.iloc[3:4,:]\n",
    "eig_vals_pc5 = eig_vals_df2.iloc[4:5,:]\n",
    "eig_vals_pc6 = eig_vals_df2.iloc[5:6,:]\n",
    "\n",
    "eig_vecs_df = pd.DataFrame(np.array(eig_vecs))\n",
    "\n",
    "eig_vecs_pc1 = eig_vecs_df.iloc[:,0:1]\n",
    "eig_vecs_pc2 = eig_vecs_df.iloc[:,1:2]\n",
    "eig_vecs_pc3 = eig_vecs_df.iloc[:,2:3]\n",
    "eig_vecs_pc4 = eig_vecs_df.iloc[:,3:4]\n",
    "eig_vecs_pc5 = eig_vecs_df.iloc[:,4:5]\n",
    "eig_vecs_pc6 = eig_vecs_df.iloc[:,5:6]\n",
    "\n",
    "#Calculate Loadings\n",
    "factor_pattern_pc1 = eig_vecs_pc1.dot(np.sqrt(eig_vals_pc1))\n",
    "factor_pattern_pc2 = eig_vecs_pc2.dot(np.sqrt(eig_vals_pc2))\n",
    "factor_pattern_pc3 = eig_vecs_pc3.dot(np.sqrt(eig_vals_pc3))\n",
    "factor_pattern_pc4 = eig_vecs_pc4.dot(np.sqrt(eig_vals_pc4))\n",
    "factor_pattern_pc5 = eig_vecs_pc5.dot(np.sqrt(eig_vals_pc5))\n",
    "factor_pattern_pc6 = eig_vecs_pc6.dot(np.sqrt(eig_vals_pc6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors = pd.concat([factor_pattern_pc1,factor_pattern_pc2,factor_pattern_pc3,factor_pattern_pc4,factor_pattern_pc5,factor_pattern_pc6], axis=1).round(2)\n",
    "\n",
    "all_factors.columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6']\n",
    "all_factors.index=features\n",
    "factor_pattern = all_factors*100\n",
    "print(\"Significant Variables In Yellow\")\n",
    "factor_pattern.style.applymap(highlight_significant)\n",
    "# all_factors.index=features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The communalities for the ith variable are computed by taking the sum of the squared loadings for that variable\n",
    "all_factors_not_rounded = pd.concat([factor_pattern_pc1,factor_pattern_pc2,factor_pattern_pc3], axis=1)\n",
    "\n",
    "communality_est = pd.DataFrame.sum(all_factors_not_rounded**2, axis=1)\n",
    "communality_est = pd.DataFrame(communality_est)\n",
    "\n",
    "communality_est.columns=[\"Final Communality Estimates\"]\n",
    "communality_est.index=features\n",
    "print(communality_est)\n",
    "\n",
    "total_communality_est = pd.DataFrame.sum(communality_est)\n",
    "print(total_communality_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Orthogonal Transformation Matrix\n",
    "def ortho_rotation(lam, method='varimax',gamma=None,\n",
    "                   eps=1e-6, itermax=100):\n",
    "    \"\"\"\n",
    "    Return orthogal rotation matrix\n",
    "    TODO: - other types beyond \n",
    "    \"\"\"\n",
    "    if gamma == None:\n",
    "        if (method == 'varimax'):\n",
    "            gamma = 1.0\n",
    "#         if (method == 'quartimax':\n",
    "#             gamma = 0.0\n",
    "\n",
    "    nrow, ncol = lam.shape\n",
    "    R = np.eye(ncol)\n",
    "    var = 0\n",
    "\n",
    "    for i in range(itermax):\n",
    "        lam_rot = np.dot(lam, R)\n",
    "        tmp = np.diag(np.sum(lam_rot ** 2, axis=0)) / nrow * gamma\n",
    "        u, s, v = np.linalg.svd(np.dot(lam.T, lam_rot ** 3 - np.dot(lam_rot, tmp)))\n",
    "        R = np.dot(u, v)\n",
    "        var_new = np.sum(s)\n",
    "        if var_new < var * (1 + eps):\n",
    "            break\n",
    "        var = var_new\n",
    "\n",
    "    return R\n",
    "\n",
    "print(\"Orthogonal Transformation Matrix\")\n",
    "pd.DataFrame(ortho_rotation(factor_pattern)).round(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
